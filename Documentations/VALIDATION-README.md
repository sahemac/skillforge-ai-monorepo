# ğŸ” Guide de Validation - User-Service SkillForge AI

Ce guide explique comment valider complÃ¨tement le User-Service avant commit GitHub.

## ğŸ“‹ PrÃ©requis

### 1. Cloud SQL Proxy
Assurez-vous que `cloud-sql-proxy` est en cours d'exÃ©cution :

```bash
# Lancer cloud-sql-proxy (remplacez PROJECT, REGION, INSTANCE)
cloud_sql_proxy -instances=PROJECT:REGION:INSTANCE=tcp:5432

# Ou avec authentication
cloud_sql_proxy -instances=skillforge-ai-mvp-25:europe-west1:skillforge-db=tcp:5432
```

### 2. Variables d'Environnement
La configuration de test utilise :
- **Database URL** : `postgresql+asyncpg://skillforge_user:Psaumes@27@127.0.0.1:5432/skillforge_db`
- **API URL** : `http://127.0.0.1:8000`

### 3. Python & DÃ©pendances
- Python 3.8+
- pip installÃ©
- DÃ©pendances dans `requirements.txt`

## ğŸš€ MÃ©thodes de Validation

### MÃ©thode 1 : Script PowerShell (RecommandÃ©)

```powershell
# Lancer la validation complÃ¨te avec installation automatique
.\run_validation.ps1
```

**Avantages** :
- âœ… Installation automatique des dÃ©pendances
- âœ… VÃ©rifications prÃ©alables
- âœ… Interface utilisateur claire
- âœ… Gestion des erreurs

### MÃ©thode 2 : Script Python Direct

```bash
# Installation manuelle des dÃ©pendances
pip install -r requirements.txt
pip install asyncpg httpx psutil pytest pytest-cov

# Lancer la validation
python validate_service.py
```

### MÃ©thode 3 : Test Rapide (Diagnostic)

```bash
# Test rapide des prÃ©requis seulement
python quick_test.py
```

**Utilisation** : Diagnostic rapide avant validation complÃ¨te

## ğŸ“Š Tests EffectuÃ©s

### 1. ğŸ“¡ **Connexion PostgreSQL**
- âœ… Test de connectivitÃ© Ã  `127.0.0.1:5432`
- âœ… VÃ©rification version PostgreSQL
- âœ… Test des permissions utilisateur
- âœ… MÃ©triques de performance connexion

### 2. ğŸ“‹ **Migrations Alembic**
- âœ… ExÃ©cution `alembic upgrade head`
- âœ… VÃ©rification historique migrations
- âœ… Validation rÃ©visions appliquÃ©es
- âœ… Test rollback potentiel

### 3. ğŸ—„ï¸ **SchÃ©ma Base de DonnÃ©es**
- âœ… VÃ©rification tables attendues :
  - `users`, `user_settings`, `user_sessions`
  - `company_profiles`, `team_members`, `subscriptions`
  - `alembic_version`
- âœ… Analyse colonnes et types
- âœ… VÃ©rification index et contraintes
- âœ… DÃ©tection tables manquantes/supplÃ©mentaires

### 4. ğŸ§ª **Tests Unitaires**
- âœ… ExÃ©cution `pytest -v --cov=app`
- âœ… Couverture de code (objectif 80%+)
- âœ… Tests authentication, users, companies
- âœ… Validation temps d'exÃ©cution

### 5. ğŸš€ **Serveur Uvicorn**
- âœ… DÃ©marrage serveur sur port 8000
- âœ… Test health check
- âœ… VÃ©rification PID et processus
- âœ… Temps de dÃ©marrage

### 6. ğŸŒ **Endpoints Critiques**
- âœ… `GET /health` - Health check
- âœ… `GET /docs` - Documentation Swagger
- âœ… `POST /api/v1/auth/register` - Inscription
- âœ… `POST /api/v1/auth/login` - Connexion
- âœ… `GET /api/v1/users/me` - Protection auth

### 7. ğŸ“Š **Validation DonnÃ©es**
- âœ… Comptage enregistrements tables
- âœ… VÃ©rification intÃ©gritÃ© donnÃ©es
- âœ… Validation emails, timestamps
- âœ… ContrÃ´le contraintes FK

## ğŸ“„ Rapport de Validation

Le script gÃ©nÃ¨re automatiquement `test-validation-report.md` contenant :

### ğŸ“Š **MÃ©triques Globales**
- Tests totaux / rÃ©ussis / Ã©chouÃ©s
- Taux de succÃ¨s
- DurÃ©e totale validation

### ğŸ” **DÃ©tails par Test**
- Statut (PASS/FAIL/WARN/SKIP)
- MÃ©triques spÃ©cifiques
- Messages d'erreur dÃ©taillÃ©s
- Recommandations

### ğŸ“ˆ **MÃ©triques Performance**
- Temps connexion DB
- Temps dÃ©marrage serveur  
- Temps rÃ©ponse endpoints
- Couverture tests

### ğŸ¯ **Recommandations**
- Actions correctives
- Optimisations suggÃ©rÃ©es
- Prochaines Ã©tapes

## ğŸš¦ Statuts de Validation

### âœ… **PASS** - Test RÃ©ussi
- FonctionnalitÃ© OK
- MÃ©triques dans les seuils
- PrÃªt pour production

### âŒ **FAIL** - Test Ã‰chouÃ©  
- Erreur critique
- **Action requise** avant commit
- Bloquer le dÃ©ploiement

### âš ï¸ **WARN** - Avertissement
- FonctionnalitÃ© partielle
- Optimisation recommandÃ©e
- Peut procÃ©der avec prudence

### â­ï¸ **SKIP** - Test IgnorÃ©
- PrÃ©requis non disponibles
- DÃ©pendance manquante
- Non critique

## ğŸ”§ RÃ©solution de ProblÃ¨mes

### Erreur : "Connection refused"
```
âŒ Erreur connexion PostgreSQL: connection refused
```

**Solutions** :
1. VÃ©rifier cloud-sql-proxy : `ps aux | grep cloud_sql_proxy`
2. Tester port : `telnet 127.0.0.1 5432`  
3. VÃ©rifier credentials database

### Erreur : "Module not found"
```
âŒ Import manquant: No module named 'asyncpg'
```

**Solutions** :
```bash
pip install asyncpg httpx psutil
# ou
pip install -r requirements.txt
```

### Erreur : "Port already in use"
```
âš ï¸ Port 8000 dÃ©jÃ  utilisÃ©
```

**Solutions** :
```bash
# Trouver le processus
lsof -i :8000
# Ou sur Windows
netstat -ano | findstr :8000

# Tuer le processus
kill -9 PID
```

### Erreur : "Tests timeout"
```
âŒ Tests timeout aprÃ¨s 5 minutes
```

**Solutions** :
1. VÃ©rifier performance DB
2. RÃ©duire scope des tests
3. Augmenter timeout dans script

### Erreur : "Alembic migration failed"
```
âŒ Erreur Alembic: target database not up to date
```

**Solutions** :
```bash
# Reset migrations
alembic downgrade base
alembic upgrade head

# Ou gÃ©nÃ©rer nouvelle migration
alembic revision --autogenerate -m "fix schema"
```

## ğŸ¯ CritÃ¨res de Validation

### âœ… **Validation RÃ©ussie** 
- Tous les tests PASS
- Couverture tests â‰¥ 80%
- Temps rÃ©ponse < 1s
- 0 erreur critique

**â¡ï¸ Action** : Commit autorisÃ©

### âŒ **Validation Ã‰chouÃ©e**
- â‰¥ 1 test FAIL
- Erreurs critiques dÃ©tectÃ©es  
- Couverture < 60%

**â¡ï¸ Action** : Correction obligatoire

### âš ï¸ **Validation Partielle**
- Tests WARN seulement
- Couverture 60-80%
- Performance dÃ©gradÃ©e

**â¡ï¸ Action** : Commit avec prudence

## ğŸ“… Utilisation dans le Workflow

### 1. **Avant DÃ©veloppement**
```bash
# Test rapide des prÃ©requis
python quick_test.py
```

### 2. **Pendant DÃ©veloppement**
```bash
# Tests unitaires seulement
python -m pytest app/tests/ -v
```

### 3. **Avant Commit**
```bash
# Validation complÃ¨te
.\run_validation.ps1
```

### 4. **En cas d'Ã‰chec**
```bash
# 1. Lire le rapport
cat test-validation-report.md

# 2. Corriger les erreurs

# 3. Re-valider
.\run_validation.ps1
```

### 5. **AprÃ¨s Validation RÃ©ussie**
```bash
# Commit safe
git add .
git commit -m "feat: user-service validated and ready"
git push origin feature/user-service
```

## ğŸ”— IntÃ©gration CI/CD

Ce script de validation peut Ãªtre intÃ©grÃ© dans le pipeline CI/CD :

```yaml
# .github/workflows/user-service-validation.yml
- name: Validate User Service
  run: |
    cd apps/backend/user-service
    python validate_service.py
  env:
    DATABASE_URL: ${{ secrets.DATABASE_URL }}
```

## ğŸ“ Support

En cas de problÃ¨me avec la validation :

1. **Consulter le rapport** : `test-validation-report.md`
2. **Logs dÃ©taillÃ©s** : Sortie console du script
3. **Tests individuels** : `python -m pytest app/tests/test_specific.py -v`
4. **Contact** : DevOps Team SkillForge AI

---

**ğŸš€ Objectif** : Garantir la qualitÃ© et la fiabilitÃ© du User-Service avant tout dÃ©ploiement

**ğŸ¯ RÃ©sultat** : Service validÃ©, testÃ© et prÃªt pour la production